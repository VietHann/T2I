# ğŸ–¼ï¸ Text-to-Image with Latent Diffusion & DiT

Dá»± Ã¡n nghiÃªn cá»©u vÃ  triá»ƒn khai mÃ´ hÃ¬nh **Text-to-Image (T2I)** dá»±a trÃªn kiáº¿n trÃºc **Latent Diffusion Model (LDM)** káº¿t há»£p vá»›i **Diffusion Transformer (DiT)**.  
Má»¥c tiÃªu lÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh sinh áº£nh cháº¥t lÆ°á»£ng cao tá»« vÄƒn báº£n **song ngá»¯ Viá»‡t/Anh**, cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng vÃ  suy luáº­n nhanh.

---

## ğŸ”‘ Äiá»ƒm ná»•i báº­t
- **Latent Diffusion**: huáº¥n luyá»‡n trÃªn khÃ´ng gian latent (VAE) â†’ tiáº¿t kiá»‡m compute.  
- **Diffusion Transformer (DiT)**: thay UNet báº±ng Transformer Ä‘á»ƒ scale tá»‘t hÆ¡n.  
- **Text Encoder SigLIP/CLIP Multilingual**: há»— trá»£ prompt tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh.  
- **Classifier-Free Guidance (CFG)**: nÃ¢ng cao Ä‘á»™ khá»›p giá»¯a áº£nh vÃ  prompt.  
- **Sampler nhanh**: DPM-Solver++, Euler A (15â€“30 bÆ°á»›c).  
- **Há»— trá»£ distillation**: suy luáº­n nhanh vá»›i 8â€“12 bÆ°á»›c.  

---

## ğŸ“ Kiáº¿n trÃºc mÃ´ hÃ¬nh

- **VAE**: nÃ©n áº£nh â†’ latent `z` (H/8 Ã— W/8 Ã— 4), decode ngÆ°á»£c khi sinh áº£nh.  
- **Text Encoder**: SigLIP/CLIP multilingual â†’ embedding cho prompt.  
- **Diffusion Core (DiT)**:
  - Patch latent thÃ nh chuá»—i tokens.  
  - ThÃªm timestep embedding.  
  - Cross-attention vá»›i text embeddings.  
  - AdaLN/FiLM Ä‘á»ƒ Ä‘iá»u kiá»‡n hoÃ¡.  
- **Loss**: v-prediction (á»•n Ä‘á»‹nh hÆ¡n Îµ-pred).  

---

## ğŸ“‚ Cáº¥u trÃºc repo

    t2i/
      configs/
        dit_b_256.yaml
        dit_b_512.yaml
      data/
        webdataset_shards/...
      models/
        vae.py
        text_encoder.py
        dit.py
        noise_scheduler.py
      train/
        dataset.py
        losses.py
        engine.py
        eval.py
      infer/
        sampler.py
        pipeline.py
      scripts/
        prepare_data.py
        train_256.sh
        finetune_512.sh
        sample.py

---

## ğŸ“¦ CÃ i Ä‘áº·t
    conda create -n t2i python=3.10 -y
    conda activate t2i
    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
    pip install -r requirements.txt

---

## ğŸ› ï¸ Chuáº©n bá»‹ dá»¯ liá»‡u

1. Táº£i táº­p **text-image** (VD: LAION, dá»¯ liá»‡u crawl riÃªng).  
2. Lá»c dá»¯ liá»‡u:
   - CLIP similarity > threshold.  
   - Aesthetic predictor > 5.  
   - Loáº¡i NSFW / caption rÃ¡c.  
3. Augmentation:
   - Song ngá»¯: prompt tiáº¿ng Viá»‡t + tiáº¿ng Anh.  
   - Resize + bucketing (512Ã—512, 640Ã—448, 448Ã—640â€¦).  
   - LÆ°u á»Ÿ dáº¡ng **WebDataset shards** (.tar).  

---

## ğŸš€ Huáº¥n luyá»‡n

### Giai Ä‘oáº¡n A: Pretrain 256px
    bash scripts/train_256.sh

- Batch size hiá»‡u dá»¥ng: 1kâ€“8k.  
- Optimizer: AdamW (lr=1e-4, cosine decay).  
- EMA decay: 0.9999.  

### Giai Ä‘oáº¡n B: Finetune 512px
    bash scripts/finetune_512.sh

- Unfreeze nháº¹ LN cuá»‘i cá»§a text encoder.  
- CÃ³ thá»ƒ unfreeze decoder VAE vÃ i epoch cuá»‘i.  

---

## ğŸ¨ Suy luáº­n

    from infer.pipeline import generate_image
    
    prompt = "Má»™t cÃ´ gÃ¡i Ä‘ang Ä‘á»c sÃ¡ch trong quÃ¡n cÃ  phÃª phong cÃ¡ch cá»• Ä‘iá»ƒn"
    images = generate_image(
        prompt=prompt,
        sampler="dpmpp",
        steps=20,
        guidance_scale=5.0,
        seed=42
    )
    images[0].save("output.png")

---

## ğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh

- **FID/KID**: Ä‘o Ä‘á»™ giá»‘ng dá»¯ liá»‡u tháº­t (COCO subset).  
- **CLIPScore**: Ä‘á»™ khá»›p prompt-áº£nh.  
- **PickScore**: cháº¥t lÆ°á»£ng áº£nh theo aesthetic.  
- **Prompt Suite**: PartiPrompts, DrawBench + bá»™ prompt tiáº¿ng Viá»‡t.  

---

## âš¡ Tá»‘i Æ°u hoÃ¡ suy luáº­n

- DPM-Solver++ ~20 bÆ°á»›c.  
- Distillation/rectified flow ~8 bÆ°á»›c.  
- Export ONNX/TensorRT cho server.  

## ğŸš€ Demo (coming soon)
![Demo Example](demo1.png)
![Demo Example](demo2.png)


